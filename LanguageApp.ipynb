{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5b9b0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.8.3-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from deep-translator) (4.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from deep-translator) (2.26.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\colli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (1.26.7)\n",
      "Installing collected packages: deep-translator\n",
      "Successfully installed deep-translator-1.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "b5124f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\colli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\colli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\colli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# xml parser\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# pytube\n",
    "from pytube import YouTube\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# translation\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "852bf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(url,language):\n",
    "    yt = YouTube(url)\n",
    "    language_mapping={'english':'a.en','german':'a.de'}\n",
    "    caption_code=language_mapping[language]\n",
    "    caption = yt.captions.get_by_language_code(caption_code)\n",
    "    xml_text=caption.xml_captions\n",
    "    root = ET.fromstring(xml_text)\n",
    "    full_text=[]\n",
    "    for word in root.iter('s'):\n",
    "        word=word.text\n",
    "        word=word.strip()\n",
    "        full_text.append(word)\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c6b18992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list,language):\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words(language)]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "582e28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(word_list):\n",
    "    word_list=np.array(word_list)\n",
    "    word_list=list(np.unique(word_list))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ca1346b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(text):\n",
    "    tagged_text=nltk.pos_tag(text)\n",
    "    nouns=[word[0] for word in tagged_text if 'NN' == word[1]]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "681aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(words):\n",
    "    translated = [GoogleTranslator(source='auto', target='en').translate(word) for word in words]\n",
    "    return dict(zip(words,translated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cbf0ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "def main(url,language):\n",
    "    text=get_caption(url,language)\n",
    "    text=remove_stopwords(text,language)\n",
    "    tagged_text=nltk.pos_tag(text)\n",
    "    #text=unique(text)\n",
    "    text=get_nouns(text)\n",
    "\n",
    "    words=nltk.FreqDist(w.lower() for w in text)\n",
    "    words=list((dict(words.most_common(10))).keys())\n",
    "\n",
    "    return translate(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "fe6f53bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colli\\AppData\\Local\\Temp/ipykernel_24652/999957230.py:5: DeprecationWarning: Call to deprecated function get_by_language_code (This object can be treated as a dictionary, i.e. captions['en']).\n",
      "  caption = yt.captions.get_by_language_code(caption_code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ja': 'and',\n",
       " 'schlaf': 'sleep',\n",
       " 'traum': 'dream',\n",
       " 'brauche': 'need',\n",
       " 'ganz': 'quite',\n",
       " 'glaube': 'believe',\n",
       " 'stunden': 'hours',\n",
       " 'schlafen': 'sleep',\n",
       " 'schon': 'beautiful',\n",
       " 'k√∂nnt': 'can'}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.youtube.com/watch?v=FzvF5ga2CvY'\n",
    "language='german'\n",
    "\n",
    "main(url,language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
